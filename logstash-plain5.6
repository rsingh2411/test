[2017-10-04T10:50:44,236][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/logstash/modules/fb_apache/configuration"}
[2017-10-04T10:50:44,242][DEBUG][logstash.plugins.registry] Adding plugin to the registry {:name=>"fb_apache", :type=>:modules, :class=>#<LogStash::Modules::Scaffold:0x2b7a7698 @kibana_version_parts=["5", "6", "0"], @module_name="fb_apache", @directory="/logstash/modules/fb_apache/configuration">}
[2017-10-04T10:50:44,243][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/logstash/modules/netflow/configuration"}
[2017-10-04T10:50:44,244][DEBUG][logstash.plugins.registry] Adding plugin to the registry {:name=>"netflow", :type=>:modules, :class=>#<LogStash::Modules::Scaffold:0x57299f27 @kibana_version_parts=["5", "6", "0"], @module_name="netflow", @directory="/logstash/modules/netflow/configuration">}
[2017-10-04T10:50:44,256][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"/logstash/data/queue"}
[2017-10-04T10:50:44,260][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"/logstash/data/dead_letter_queue"}
[2017-10-04T10:50:44,293][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"41e9c739-9152-4986-98e4-4af1a4dea2ac", :path=>"/logstash/data/uuid"}
[2017-10-04T10:50:44,310][DEBUG][logstash.agent           ] Agent: Configuring metric collection
[2017-10-04T10:50:44,313][DEBUG][logstash.instrument.periodicpoller.os] PeriodicPoller: Starting {:polling_interval=>5, :polling_timeout=>120}
[2017-10-04T10:50:44,336][DEBUG][logstash.instrument.periodicpoller.jvm] PeriodicPoller: Starting {:polling_interval=>5, :polling_timeout=>120}
[2017-10-04T10:50:44,381][DEBUG][logstash.instrument.periodicpoller.persistentqueue] PeriodicPoller: Starting {:polling_interval=>5, :polling_timeout=>120}
[2017-10-04T10:50:44,385][DEBUG][logstash.instrument.periodicpoller.deadletterqueue] PeriodicPoller: Starting {:polling_interval=>5, :polling_timeout=>120}
[2017-10-04T10:50:44,392][DEBUG][logstash.agent           ] Reading config file {:config_file=>"/test.conf"}
[2017-10-04T10:50:44,463][DEBUG][logstash.plugins.registry] On demand adding plugin to the registry {:name=>"kafka", :type=>"input", :class=>LogStash::Inputs::Kafka}
[2017-10-04T10:50:44,481][DEBUG][logstash.plugins.registry] On demand adding plugin to the registry {:name=>"json", :type=>"codec", :class=>LogStash::Codecs::JSON}
[2017-10-04T10:50:44,485][DEBUG][logstash.codecs.json     ] config LogStash::Codecs::JSON/@id = "json_ccc45766-6059-4dbd-9506-7d032b750e82"
[2017-10-04T10:50:44,486][DEBUG][logstash.codecs.json     ] config LogStash::Codecs::JSON/@enable_metric = true
[2017-10-04T10:50:44,487][DEBUG][logstash.codecs.json     ] config LogStash::Codecs::JSON/@charset = "UTF-8"
[2017-10-04T10:50:44,491][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@codec = <LogStash::Codecs::JSON id=>"json_ccc45766-6059-4dbd-9506-7d032b750e82", enable_metric=>true, charset=>"UTF-8">
[2017-10-04T10:50:44,491][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@bootstrap_servers = "10.0.20.50:4000,10.0.20.50:4001,10.0.20.4:4000,10.0.20.4:4001,10.0.20.62:4000,10.0.20.62:4001"
[2017-10-04T10:50:44,491][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@group_id = "logstash"
[2017-10-04T10:50:44,492][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@topics = ["logstash_logs"]
[2017-10-04T10:50:44,492][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@consumer_threads = 1
[2017-10-04T10:50:44,492][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@id = "58f8b2c9d6c575a2ed99e8256dc4a43fd1885aa0-1"
[2017-10-04T10:50:44,492][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@enable_metric = true
[2017-10-04T10:50:44,493][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@add_field = {}
[2017-10-04T10:50:44,493][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@auto_commit_interval_ms = "5000"
[2017-10-04T10:50:44,493][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@client_id = "logstash"
[2017-10-04T10:50:44,493][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@enable_auto_commit = "true"
[2017-10-04T10:50:44,494][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@key_deserializer_class = "org.apache.kafka.common.serialization.StringDeserializer"
[2017-10-04T10:50:44,494][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@value_deserializer_class = "org.apache.kafka.common.serialization.StringDeserializer"
[2017-10-04T10:50:44,494][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@poll_timeout_ms = 100
[2017-10-04T10:50:44,494][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@ssl = false
[2017-10-04T10:50:44,495][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@security_protocol = "PLAINTEXT"
[2017-10-04T10:50:44,495][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@sasl_mechanism = "GSSAPI"
[2017-10-04T10:50:44,495][DEBUG][logstash.inputs.kafka    ] config LogStash::Inputs::Kafka/@decorate_events = false
[2017-10-04T10:50:44,499][DEBUG][logstash.plugins.registry] On demand adding plugin to the registry {:name=>"rubydebug", :type=>"codec", :class=>LogStash::Codecs::RubyDebug}
[2017-10-04T10:50:44,503][DEBUG][logstash.codecs.rubydebug] config LogStash::Codecs::RubyDebug/@metadata = true
[2017-10-04T10:50:44,503][DEBUG][logstash.codecs.rubydebug] config LogStash::Codecs::RubyDebug/@id = "58f8b2c9d6c575a2ed99e8256dc4a43fd1885aa0-2"
[2017-10-04T10:50:44,504][DEBUG][logstash.codecs.rubydebug] config LogStash::Codecs::RubyDebug/@enable_metric = true
[2017-10-04T10:50:44,611][DEBUG][logstash.plugins.registry] On demand adding plugin to the registry {:name=>"stdout", :type=>"output", :class=>LogStash::Outputs::Stdout}
[2017-10-04T10:50:44,618][DEBUG][logstash.codecs.rubydebug] config LogStash::Codecs::RubyDebug/@metadata = true
[2017-10-04T10:50:44,620][DEBUG][logstash.codecs.rubydebug] config LogStash::Codecs::RubyDebug/@id = "58f8b2c9d6c575a2ed99e8256dc4a43fd1885aa0-2"
[2017-10-04T10:50:44,620][DEBUG][logstash.codecs.rubydebug] config LogStash::Codecs::RubyDebug/@enable_metric = true
[2017-10-04T10:50:44,626][DEBUG][logstash.outputs.stdout  ] config LogStash::Outputs::Stdout/@codec = <LogStash::Codecs::RubyDebug metadata=>true, id=>"58f8b2c9d6c575a2ed99e8256dc4a43fd1885aa0-2", enable_metric=>true>
[2017-10-04T10:50:44,626][DEBUG][logstash.outputs.stdout  ] config LogStash::Outputs::Stdout/@id = "58f8b2c9d6c575a2ed99e8256dc4a43fd1885aa0-3"
[2017-10-04T10:50:44,626][DEBUG][logstash.outputs.stdout  ] config LogStash::Outputs::Stdout/@enable_metric = true
[2017-10-04T10:50:44,627][DEBUG][logstash.outputs.stdout  ] config LogStash::Outputs::Stdout/@workers = 1
[2017-10-04T10:50:44,642][DEBUG][logstash.agent           ] starting agent
[2017-10-04T10:50:44,646][DEBUG][logstash.agent           ] starting pipeline {:id=>"main"}
[2017-10-04T10:50:44,657][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2017-10-04T10:50:44,677][INFO ][logstash.pipeline        ] Pipeline main started
[2017-10-04T10:50:44,692][DEBUG][logstash.agent           ] Starting puma
[2017-10-04T10:50:44,695][DEBUG][logstash.agent           ] Trying to start WebServer {:port=>9600}
[2017-10-04T10:50:44,703][DEBUG][logstash.api.service     ] [api-service] start
[2017-10-04T10:50:44,767][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-10-04T10:50:44,808][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig] ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [10.0.20.50:4000, 10.0.20.50:4001, 10.0.20.4:4000, 10.0.20.4:4001, 10.0.20.62:4000, 10.0.20.62:4001]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = logstash-0
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = logstash
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

[2017-10-04T10:50:44,810][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer] Starting the Kafka consumer
[2017-10-04T10:50:44,838][DEBUG][org.apache.kafka.clients.Metadata] Updated cluster metadata version 1 to Cluster(nodes = [10.0.20.62:4001 (id: -6 rack: null), 10.0.20.4:4000 (id: -3 rack: null), 10.0.20.4:4001 (id: -4 rack: null), 10.0.20.62:4000 (id: -5 rack: null), 10.0.20.50:4000 (id: -1 rack: null), 10.0.20.50:4001 (id: -2 rack: null)], partitions = [])
[2017-10-04T10:50:44,858][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name connections-closed:
[2017-10-04T10:50:44,861][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name connections-created:
[2017-10-04T10:50:44,862][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name bytes-sent-received:
[2017-10-04T10:50:44,863][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name bytes-sent:
[2017-10-04T10:50:44,865][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name bytes-received:
[2017-10-04T10:50:44,866][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name select-time:
[2017-10-04T10:50:44,866][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name io-time:
[2017-10-04T10:50:44,880][INFO ][org.apache.kafka.clients.consumer.ConsumerConfig] ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [10.0.20.50:4000, 10.0.20.50:4001, 10.0.20.4:4000, 10.0.20.4:4001, 10.0.20.62:4000, 10.0.20.62:4001]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = logstash-0
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	group.id = logstash
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

[2017-10-04T10:50:44,901][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name heartbeat-latency
[2017-10-04T10:50:44,903][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name join-latency
[2017-10-04T10:50:44,904][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name sync-latency
[2017-10-04T10:50:44,909][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name commit-latency
[2017-10-04T10:50:44,922][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name bytes-fetched
[2017-10-04T10:50:44,922][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name records-fetched
[2017-10-04T10:50:44,923][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name fetch-latency
[2017-10-04T10:50:44,924][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name records-lag
[2017-10-04T10:50:44,924][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name fetch-throttle-time
[2017-10-04T10:50:44,929][INFO ][org.apache.kafka.common.utils.AppInfoParser] Kafka version : 0.10.0.1
[2017-10-04T10:50:44,929][INFO ][org.apache.kafka.common.utils.AppInfoParser] Kafka commitId : a7a17cdec9eaa6c5
[2017-10-04T10:50:44,931][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer] Kafka consumer created
[2017-10-04T10:50:44,935][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer] Subscribed to topic(s): logstash_logs
[2017-10-04T10:50:44,936][DEBUG][org.apache.kafka.clients.consumer.internals.AbstractCoordinator] Sending coordinator request for group logstash to broker 10.0.20.4:4000 (id: -3 rack: null)
[2017-10-04T10:50:44,974][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node -3 at 10.0.20.4:4000.
[2017-10-04T10:50:44,985][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name node--3.bytes-sent
[2017-10-04T10:50:44,986][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name node--3.bytes-received
[2017-10-04T10:50:44,986][DEBUG][org.apache.kafka.common.metrics.Metrics] Added sensor with name node--3.latency
[2017-10-04T10:50:44,987][DEBUG][org.apache.kafka.clients.NetworkClient] Completed connection to node -3
[2017-10-04T10:50:45,076][DEBUG][org.apache.kafka.clients.NetworkClient] Sending metadata request {topics=[logstash_logs]} to node -3
[2017-10-04T10:50:45,100][DEBUG][org.apache.kafka.clients.Metadata] Updated cluster metadata version 2 to Cluster(nodes = [thor12-worker-1:4000 (id: 3 rack: null), thor12-worker-4:4000 (id: 1 rack: null), thor12-worker-3:4000 (id: 2 rack: null)], partitions = [Partition(topic = logstash_logs, partition = 1, leader = 2, replicas = [2,3,1,], isr = [2,3,1,], Partition(topic = logstash_logs, partition = 2, leader = 3, replicas = [3,1,2,], isr = [3,1,2,], Partition(topic = logstash_logs, partition = 0, leader = 1, replicas = [1,2,3,], isr = [1,2,3,], Partition(topic = logstash_logs, partition = 5, leader = 3, replicas = [3,2,1,], isr = [3,2,1,], Partition(topic = logstash_logs, partition = 3, leader = 1, replicas = [1,3,2,], isr = [1,3,2,], Partition(topic = logstash_logs, partition = 4, leader = 2, replicas = [2,1,3,], isr = [2,1,3,]])
[2017-10-04T10:50:45,103][DEBUG][org.apache.kafka.clients.consumer.internals.AbstractCoordinator] Received group coordinator response ClientResponse(receivedTimeMs=1507114245102, disconnected=false, request=ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@28db362d, request=RequestSend(header={api_key=10,api_version=0,correlation_id=0,client_id=logstash-0}, body={group_id=logstash}), createdTimeMs=1507114244968, sendTimeMs=1507114245078), responseBody={error_code=0,coordinator={node_id=1,host=thor12-worker-4,port=4000}})
[2017-10-04T10:50:45,104][INFO ][org.apache.kafka.clients.consumer.internals.AbstractCoordinator] Discovered coordinator thor12-worker-4:4000 (id: 2147483646 rack: null) for group logstash.
[2017-10-04T10:50:45,104][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 2147483646 at thor12-worker-4:4000.
[2017-10-04T10:50:49,678][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:50:50,115][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 2147483646 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:159) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.tryConnect(ConsumerNetworkClient.java:408) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handleGroupMetadataResponse(AbstractCoordinator.java:507) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.access$1200(AbstractCoordinator.java:81) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$2.onSuccess(AbstractCoordinator.java:482) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$2.onSuccess(AbstractCoordinator.java:479) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:167) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:133) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:107) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.onComplete(ConsumerNetworkClient.java:426) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:278) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 49 more
[2017-10-04T10:50:50,120][INFO ][org.apache.kafka.clients.consumer.internals.AbstractCoordinator] Marking the coordinator thor12-worker-4:4000 (id: 2147483646 rack: null) dead for group logstash
[2017-10-04T10:50:50,120][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:50:50,120][DEBUG][org.apache.kafka.clients.consumer.internals.AbstractCoordinator] Sending coordinator request for group logstash to broker thor12-worker-1:4000 (id: 3 rack: null)
[2017-10-04T10:50:50,121][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 3 at thor12-worker-1:4000.
[2017-10-04T10:50:54,680][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:50:55,124][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 3 at thor12-worker-1:4000:
java.io.IOException: Can't resolve address: thor12-worker-1:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:159) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.trySend(ConsumerNetworkClient.java:349) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:219) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 39 more
[2017-10-04T10:50:55,125][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 1 for sending metadata request
[2017-10-04T10:50:55,125][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 1 at thor12-worker-4:4000.
[2017-10-04T10:50:55,126][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 1 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:163) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:179) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:50:55,128][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient] Cancelled GROUP_COORDINATOR request ClientRequest(expectResponse=true, callback=org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler@5fca4a1, request=RequestSend(header={api_key=10,api_version=0,correlation_id=2,client_id=logstash-0}, body={group_id=logstash}), createdTimeMs=1507114250121, sendTimeMs=0) with correlation id 2 due to node 3 being disconnected
[2017-10-04T10:50:55,128][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:50:55,128][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 2 for sending metadata request
[2017-10-04T10:50:55,128][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 2 at thor12-worker-3:4000.
[2017-10-04T10:50:59,679][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:00,134][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 2 at thor12-worker-3:4000:
java.io.IOException: Can't resolve address: thor12-worker-3:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:00,136][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:00,136][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 1 for sending metadata request
[2017-10-04T10:51:00,136][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 1 at thor12-worker-4:4000.
[2017-10-04T10:51:04,681][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:05,143][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 1 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:05,144][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:05,145][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 1 for sending metadata request
[2017-10-04T10:51:05,145][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 1 at thor12-worker-4:4000.
[2017-10-04T10:51:05,145][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 1 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:05,146][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 3 for sending metadata request
[2017-10-04T10:51:05,146][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 3 at thor12-worker-1:4000.
[2017-10-04T10:51:09,682][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:10,150][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 3 at thor12-worker-1:4000:
java.io.IOException: Can't resolve address: thor12-worker-1:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:10,152][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:10,152][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 3 for sending metadata request
[2017-10-04T10:51:10,152][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 3 at thor12-worker-1:4000.
[2017-10-04T10:51:10,153][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 3 at thor12-worker-1:4000:
java.io.IOException: Can't resolve address: thor12-worker-1:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:10,154][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 1 for sending metadata request
[2017-10-04T10:51:10,154][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 1 at thor12-worker-4:4000.
[2017-10-04T10:51:10,155][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 1 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:10,157][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 2 for sending metadata request
[2017-10-04T10:51:10,157][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 2 at thor12-worker-3:4000.
[2017-10-04T10:51:14,683][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:15,163][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 2 at thor12-worker-3:4000:
java.io.IOException: Can't resolve address: thor12-worker-3:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:15,166][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:15,166][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 2 for sending metadata request
[2017-10-04T10:51:15,167][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 2 at thor12-worker-3:4000.
[2017-10-04T10:51:15,167][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 2 at thor12-worker-3:4000:
java.io.IOException: Can't resolve address: thor12-worker-3:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:15,168][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 1 for sending metadata request
[2017-10-04T10:51:15,168][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 1 at thor12-worker-4:4000.
[2017-10-04T10:51:19,683][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:20,173][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 1 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:20,178][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:20,178][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 3 for sending metadata request
[2017-10-04T10:51:20,179][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 3 at thor12-worker-1:4000.
[2017-10-04T10:51:24,684][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:25,184][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 3 at thor12-worker-1:4000:
java.io.IOException: Can't resolve address: thor12-worker-1:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:25,186][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:25,186][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 1 for sending metadata request
[2017-10-04T10:51:25,186][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 1 at thor12-worker-4:4000.
[2017-10-04T10:51:25,187][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 1 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:25,189][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 2 for sending metadata request
[2017-10-04T10:51:25,189][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 2 at thor12-worker-3:4000.
[2017-10-04T10:51:29,685][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:30,193][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 2 at thor12-worker-3:4000:
java.io.IOException: Can't resolve address: thor12-worker-3:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:30,194][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:30,195][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 3 for sending metadata request
[2017-10-04T10:51:30,195][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 3 at thor12-worker-1:4000.
[2017-10-04T10:51:30,195][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 3 at thor12-worker-1:4000:
java.io.IOException: Can't resolve address: thor12-worker-1:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:30,196][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 1 for sending metadata request
[2017-10-04T10:51:30,197][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 1 at thor12-worker-4:4000.
[2017-10-04T10:51:34,685][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:35,200][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 1 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:35,201][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:35,202][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 3 for sending metadata request
[2017-10-04T10:51:35,202][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 3 at thor12-worker-1:4000.
[2017-10-04T10:51:39,685][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:40,207][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 3 at thor12-worker-1:4000:
java.io.IOException: Can't resolve address: thor12-worker-1:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:40,208][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:40,209][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 2 for sending metadata request
[2017-10-04T10:51:40,209][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 2 at thor12-worker-3:4000.
[2017-10-04T10:51:44,685][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:45,215][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 2 at thor12-worker-3:4000:
java.io.IOException: Can't resolve address: thor12-worker-3:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:45,216][DEBUG][org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] Cannot auto-commit offsets for group logstash since the coordinator is unknown
[2017-10-04T10:51:45,216][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 3 for sending metadata request
[2017-10-04T10:51:45,217][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 3 at thor12-worker-1:4000.
[2017-10-04T10:51:45,217][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 3 at thor12-worker-1:4000:
java.io.IOException: Can't resolve address: thor12-worker-1:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:45,219][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 2 for sending metadata request
[2017-10-04T10:51:45,219][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 2 at thor12-worker-3:4000.
[2017-10-04T10:51:45,219][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 2 at thor12-worker-3:4000:
java.io.IOException: Can't resolve address: thor12-worker-3:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:45,221][DEBUG][org.apache.kafka.clients.NetworkClient] Initialize connection to node 1 for sending metadata request
[2017-10-04T10:51:45,221][DEBUG][org.apache.kafka.clients.NetworkClient] Initiating connection to node 1 at thor12-worker-4:4000.
[2017-10-04T10:51:46,673][DEBUG][logstash.instrument.periodicpoller.os] PeriodicPoller: Stopping
[2017-10-04T10:51:46,674][DEBUG][logstash.instrument.periodicpoller.jvm] PeriodicPoller: Stopping
[2017-10-04T10:51:46,674][DEBUG][logstash.instrument.periodicpoller.persistentqueue] PeriodicPoller: Stopping
[2017-10-04T10:51:46,674][DEBUG][logstash.instrument.periodicpoller.deadletterqueue] PeriodicPoller: Stopping
[2017-10-04T10:51:46,678][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2017-10-04T10:51:46,683][DEBUG][logstash.pipeline        ] Closing inputs
[2017-10-04T10:51:46,683][DEBUG][logstash.inputs.kafka    ] stopping {:plugin=>"LogStash::Inputs::Kafka"}
[2017-10-04T10:51:46,683][DEBUG][logstash.pipeline        ] Closed inputs
[2017-10-04T10:51:49,684][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:50,226][DEBUG][org.apache.kafka.clients.NetworkClient] Error connecting to node 1 at thor12-worker-4:4000:
java.io.IOException: Can't resolve address: thor12-worker-4:4000
	at org.apache.kafka.common.network.Selector.connect(Selector.java:171) ~[kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:498) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.access$400(NetworkClient.java:48) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:645) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:552) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:258) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.clientPoll(ConsumerNetworkClient.java:360) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:224) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:134) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:183) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:974) [kafka-clients-0.10.0.1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:938) [kafka-clients-0.10.0.1.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92-internal]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92-internal]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92-internal]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92-internal]
	at org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:451) [?:?]
	at org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:312) [?:?]
	at org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:45) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:326) [?:?]
	at org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:170) [?:?]
	at org.jruby.ast.CallOneArgNode.interpret(CallOneArgNode.java:57) [?:?]
	at org.jruby.ast.DAsgnNode.interpret(DAsgnNode.java:110) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.WhileNode.interpret(WhileNode.java:131) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.ast.BlockNode.interpret(BlockNode.java:71) [?:?]
	at org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) [?:?]
	at org.jruby.ast.RescueNode.interpret(RescueNode.java:116) [?:?]
	at org.jruby.ast.EnsureNode.interpret(EnsureNode.java:96) [?:?]
	at org.jruby.ast.BeginNode.interpret(BeginNode.java:83) [?:?]
	at org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) [?:?]
	at org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) [?:?]
	at org.jruby.runtime.Interpreted19Block.evalBlockBody(Interpreted19Block.java:206) [?:?]
	at org.jruby.runtime.Interpreted19Block.yield(Interpreted19Block.java:194) [?:?]
	at org.jruby.runtime.Interpreted19Block.call(Interpreted19Block.java:125) [?:?]
	at org.jruby.runtime.Block.call(Block.java:101) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:300) [?:?]
	at org.jruby.RubyProc.call(RubyProc.java:230) [?:?]
	at org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:103) [?:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_92-internal]
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101) ~[?:1.8.0_92-internal]
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622) ~[?:1.8.0_92-internal]
	at org.apache.kafka.common.network.Selector.connect(Selector.java:168) ~[kafka-clients-0.10.0.1.jar:?]
	... 42 more
[2017-10-04T10:51:50,234][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name connections-closed:
[2017-10-04T10:51:50,234][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name connections-created:
[2017-10-04T10:51:50,234][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name bytes-sent-received:
[2017-10-04T10:51:50,235][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name bytes-sent:
[2017-10-04T10:51:50,235][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name bytes-received:
[2017-10-04T10:51:50,236][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name select-time:
[2017-10-04T10:51:50,236][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name io-time:
[2017-10-04T10:51:50,237][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name node--3.bytes-sent
[2017-10-04T10:51:50,237][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name node--3.bytes-received
[2017-10-04T10:51:50,237][DEBUG][org.apache.kafka.common.metrics.Metrics] Removed sensor with name node--3.latency
[2017-10-04T10:51:50,238][DEBUG][org.apache.kafka.clients.consumer.KafkaConsumer] The Kafka consumer has closed.
[2017-10-04T10:51:50,238][DEBUG][logstash.inputs.kafka    ] closing {:plugin=>"LogStash::Inputs::Kafka"}
[2017-10-04T10:51:50,239][DEBUG][logstash.pipeline        ] Input plugins stopped! Will shutdown filter/output workers.
[2017-10-04T10:51:50,286][DEBUG][logstash.pipeline        ] Pushing flush onto pipeline
[2017-10-04T10:51:50,287][DEBUG][logstash.pipeline        ] Pushing shutdown {:thread=>"#<Thread:0x48a1bd67 sleep>"}
[2017-10-04T10:51:50,287][DEBUG][logstash.pipeline        ] Pushing shutdown {:thread=>"#<Thread:0x359cb343 run>"}
[2017-10-04T10:51:50,288][DEBUG][logstash.pipeline        ] Pushing shutdown {:thread=>"#<Thread:0x182ec0ac sleep>"}
[2017-10-04T10:51:50,288][DEBUG][logstash.pipeline        ] Pushing shutdown {:thread=>"#<Thread:0x4f900f30 sleep>"}
[2017-10-04T10:51:50,288][DEBUG][logstash.pipeline        ] Shutdown waiting for worker thread #<Thread:0x48a1bd67>
[2017-10-04T10:51:50,331][DEBUG][logstash.pipeline        ] Shutdown waiting for worker thread #<Thread:0x359cb343>
[2017-10-04T10:51:50,331][DEBUG][logstash.pipeline        ] Shutdown waiting for worker thread #<Thread:0x182ec0ac>
[2017-10-04T10:51:50,332][DEBUG][logstash.pipeline        ] Shutdown waiting for worker thread #<Thread:0x4f900f30>
[2017-10-04T10:51:50,332][DEBUG][logstash.outputs.stdout  ] closing {:plugin=>"LogStash::Outputs::Stdout"}
[2017-10-04T10:51:50,333][DEBUG][logstash.pipeline        ] Pipeline main has been shutdown
